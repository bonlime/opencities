{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T17:03:01.466109Z",
     "start_time": "2020-03-29T17:03:01.446036Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:100% !important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:100% !important;}</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T17:03:04.663078Z",
     "start_time": "2020-03-29T17:03:02.302774Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as albu\n",
    "import albumentations.pytorch as albu_pt\n",
    "from sklearn.metrics import jaccard_score\n",
    "%matplotlib inline\n",
    "\n",
    "import apex\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "import pytorch_tools as pt\n",
    "\n",
    "from src.dataset import OpenCitiesDataset, OpenCitiesTestDataset, InriaTilesDataset, get_dataloaders\n",
    "from src.augmentations import get_aug\n",
    "from src.callbacks import ThrJaccardScore\n",
    "from pytorch_tools.fit_wrapper.callbacks import SegmCutmix\n",
    "from pytorch_tools.tta_wrapper import TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T17:03:04.686226Z",
     "start_time": "2020-03-29T17:03:04.665393Z"
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "from src.utils import MODEL_FROM_NAME\n",
    "from src.utils import TargetWrapper\n",
    "from pytorch_tools.fit_wrapper.callbacks import Callback\n",
    "from pytorch_tools.utils.misc import to_numpy\n",
    "from src.utils import criterion_from_list\n",
    "from src.utils import ToCudaLoader\n",
    "from src.dataset import get_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T17:03:04.706371Z",
     "start_time": "2020-03-29T17:03:04.687623Z"
    }
   },
   "outputs": [],
   "source": [
    "# BS = 32\n",
    "# train_dtld_gpu , val_dtld_gpu = get_dataloaders(\n",
    "#     [\n",
    "#         \"tier1\", \n",
    "# #         \"tier2\"\n",
    "#     ],\n",
    "#     batch_size=BS\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T17:03:05.865235Z",
     "start_time": "2020-03-29T17:03:05.844508Z"
    }
   },
   "outputs": [],
   "source": [
    "val_aug = get_aug(\"val\", size=384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T17:04:16.238724Z",
     "start_time": "2020-03-29T17:04:16.013367Z"
    }
   },
   "outputs": [],
   "source": [
    "# val_tier1 = OpenCitiesDataset(\n",
    "#     split=\"val\",\n",
    "#     transform=val_aug,\n",
    "#     imgs_path=\"data/tier_1-images-512\",\n",
    "#     masks_path=\"data/tier_1-masks-512\",\n",
    "# )\n",
    "# val_tier1_bo = OpenCitiesDataset(\n",
    "#     split=\"val\",\n",
    "#     transform=val_aug,\n",
    "#     imgs_path=\"data/tier_1-images-512\",\n",
    "#     masks_path=\"data/tier_1-masks-512\",\n",
    "#     buildings_only=True,\n",
    "# )\n",
    "# val_tier2 = OpenCitiesDataset(\n",
    "#     split=\"val\",\n",
    "#     transform=val_aug,\n",
    "#     imgs_path=\"data/tier_2-images-512\",\n",
    "#     masks_path=\"data/tier_2-masks-512\",\n",
    "# )\n",
    "# test_dataset512 = OpenCitiesTestDataset(transform=get_aug(\"test\", size=512))\n",
    "# test_dataset384 = OpenCitiesTestDataset(transform=get_aug(\"test\", size=384))\n",
    "\n",
    "val_inria384 = InriaTilesDataset(split=\"val\", transform=val_aug)\n",
    "val_inria512 = InriaTilesDataset(split=\"val\", transform=get_aug(\"val\", size=512))\n",
    "val_inria768 = InriaTilesDataset(split=\"val\", transform=get_aug(\"val\", size=768))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T17:04:16.439597Z",
     "start_time": "2020-03-29T17:04:16.417230Z"
    }
   },
   "outputs": [],
   "source": [
    "def auto_canny(image, sigma=0.33, fixed_thr=False):\n",
    "    if image.max() <= 1:\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "#     image = cv2.blur(image, (11, 11))\n",
    "    is_image = False\n",
    "    if len(image.shape) == 3 and image.shape[2] == 3:\n",
    "        is_image = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    # compute the median of the single channel pixel intensities\n",
    "    v = np.median(image)\n",
    "    # apply automatic Canny edge detection using the computed median\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    if fixed_thr:\n",
    "        lower, upper = 160, 200\n",
    "    edged = cv2.Canny(image, lower, upper)\n",
    "    # return the edged image\n",
    "    if is_image:\n",
    "        return np.stack([edged] * 3, axis=2) / 255\n",
    "    else:\n",
    "        return edged / 255\n",
    "\n",
    "def remove_model_from_name(state_dict):\n",
    "    new_sd = {}\n",
    "    for k, v in state_dict:\n",
    "        new_sd[k[6:]] = v\n",
    "    return \n",
    "\n",
    "def process_adaptive_thr(pred):\n",
    "    thr_mask = cv2.threshold(\n",
    "        (pred * 255).astype(np.uint8),0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU\n",
    "    )[1] / 255\n",
    "    thr_mask[pred < 0.2] = 0\n",
    "    return thr_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T17:04:16.670253Z",
     "start_time": "2020-03-29T17:04:16.645701Z"
    }
   },
   "outputs": [],
   "source": [
    "PREV_WEIGHTS = None\n",
    "PREV_MODEL = None\n",
    "SINGLE_IMG = None\n",
    "SINGLE_MASK = None\n",
    "MEAN=(0.485, 0.456, 0.406)\n",
    "STD=(0.229, 0.224, 0.225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T17:04:17.693615Z",
     "start_time": "2020-03-29T17:04:17.671835Z"
    }
   },
   "outputs": [],
   "source": [
    "# DATASETS = {\"val_tier1\" : val_tier1, \"val_tier1_bo\": val_tier1_bo, \"val_tier2\" : val_tier2, \"test512\": test_dataset512, \"test384\": test_dataset384 }\n",
    "DATASETS = {\"val_inria384\": val_inria384, \"val_inria512\": val_inria512, \"val_inria768\": val_inria768}\n",
    "OFFSET = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T17:44:50.833689Z",
     "start_time": "2020-03-29T17:44:50.405399Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56120bc323fe452687214d34e877f156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='dataset', options=('val_inria384', 'val_inria512', 'val_inria768')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(\n",
    "    weights=sorted(os.listdir(\"logs/\")),\n",
    "    N=widgets.IntSlider(min=0, max=32, continuous_update=False),\n",
    "    offset=(0, 2000, 100),\n",
    "    thr=widgets.FloatSlider(0.5, min=0.2, max=0.8, step=0.1, continuous_update=False),\n",
    "    \n",
    ")\n",
    "def foo(\n",
    "    dataset=DATASETS.keys(),\n",
    "    weights=None, N=0, offset=0, thr=0.5, adaptive_thr=False, use_tta=False, \n",
    "    equilize=False, detect_edges=False, watershed=False, overlay_pred=False, overlay_true=False,\n",
    "    use_gmean=False,\n",
    "):\n",
    "    global PREV_WEIGHTS\n",
    "    global PREV_MODEL\n",
    "    global SINGLE_IMG\n",
    "    global SINGLE_PRED\n",
    "    \n",
    "    if weights is None:\n",
    "        print(\"select weights\")\n",
    "        return \n",
    "    \n",
    "    if weights != PREV_WEIGHTS:\n",
    "        PREV_WEIGHTS = weights\n",
    "        log_path = \"logs/\" + weights + \"/\"\n",
    "        config = yaml.load(open(log_path + \"config.yaml\"))\n",
    "        model = MODEL_FROM_NAME[config[\"segm_arch\"]](config[\"arch\"], **config.get(\"model_params\", {})).cuda()\n",
    "        state_dict = torch.load(log_path + 'model.chpn')[\"state_dict\"]\n",
    "        if \"model.\" in list(state_dict.keys())[0]:\n",
    "            # model was trained using tta need to remove `model` from name\n",
    "            state_dict = {k[6:]:v for k,v in state_dict.items()}\n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "        model.eval()\n",
    "        PREV_MODEL = model\n",
    "\n",
    "    if \"test\" in dataset:\n",
    "        _, img, _ = DATASETS[dataset][N + offset]\n",
    "        mask = torch.zeros_like(img)\n",
    "    else:\n",
    "        img, mask = DATASETS[dataset][N + offset]\n",
    "    if \"dali\" in PREV_WEIGHTS:\n",
    "#         print(img.max(), img.min())\n",
    "        input_img = img * torch.Tensor(STD).view(1, 3, 1, 1) + torch.Tensor(MEAN).view(1, 3, 1, 1)\n",
    "#         print(input_img.max(), input_img.min())\n",
    "        input_img = (input_img - 0.5 ) / 0.5\n",
    "#         print(input_img.max(), input_img.min())\n",
    "    else:\n",
    "        input_img = img\n",
    "    with torch.no_grad():\n",
    "        if use_tta:\n",
    "            model = pt.tta_wrapper.TTA(PREV_MODEL, segm=True, h_flip=True, rotation=[90], merge=\"gmean\" if use_gmean else \"mean\", activation=\"sigmoid\")\n",
    "        else:\n",
    "            model = PREV_MODEL\n",
    "        pred = model(input_img.view(1, *img.shape).cuda())\n",
    "        if not use_tta:\n",
    "            pred.sigmoid_()\n",
    "    \n",
    "    img = to_numpy(img).swapaxes(0, 2)\n",
    "    img = np.clip((img * STD + MEAN), 0, 1)\n",
    "    if equilize:\n",
    "        img = albu.Equalize(always_apply=True, by_channels=False)(image=(img * 255).astype(np.uint8))[\"image\"] / 255\n",
    "    \n",
    "    mask = to_numpy(mask).swapaxes(0, 2)\n",
    "    mask[:, :, :2] = (mask[:, :, :2] + 1) * 0.5\n",
    "    pred = to_numpy(pred.squeeze())\n",
    "    if detect_edges:\n",
    "        img = auto_canny(img, fixed_thr=True, sigma=0.5)\n",
    "        pred = auto_canny(pred, fixed_thr=True)\n",
    "    thr_mask = (pred > thr).astype(np.uint8)\n",
    "    if adaptive_thr:\n",
    "        thr_mask = process_adaptive_thr(pred)\n",
    "    \n",
    "    score = jaccard_score(mask[:,:,2], thr_mask.T, average=\"micro\")\n",
    "    if mask[:,:, 2].sum() == 0 and thr_mask.sum() == 0:\n",
    "        score = 1\n",
    "#     if watershed: \n",
    "#         img, pred = watershed(img, pred)\n",
    "    if overlay_pred:\n",
    "        img[thr_mask.T == 1] = [1, 0, 0]\n",
    "    if overlay_true:\n",
    "        img[mask[:, :, 2] == 1] = [0, 0, 1]\n",
    "        if overlay_pred:\n",
    "            img[(mask[:, :, 2] == 1) & (thr_mask.T == 1)] = [1, 0, 1]\n",
    "    pred = np.stack([pred.T] * 3, 2)\n",
    "    thr_mask = np.stack([thr_mask.T] * 3, 2)\n",
    "    stacked = np.hstack([img, mask, pred, thr_mask])\n",
    "    plt.figure(figsize=(32,8))\n",
    "    plt.imshow(stacked, cmap=\"gray\")\n",
    "    plt.title(f\"Jaccard={score:.3f}\", fontdict={\"fontsize\": 25})\n",
    "    plt.axis(\"off\")\n",
    "    SINGLE_IMG = pred\n",
    "    SINGLE_PRED = thr_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Results Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T11:48:43.340834Z",
     "start_time": "2020-03-29T11:48:42.990172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.bifpn_2l_2dtst_reduced_focal_20200303_202324\r\n",
      "10.bifpn_2l_3dtst_reduced_focal_20200303_205035\r\n",
      "11.bifpn_2l_2dtst_lookahead_cut_20200304_180726\r\n",
      "11.bifpn_2l_2dtst_seres101_20200304_233016\r\n",
      "11.bifpn_2l_2dtst_seres101_resume_20200305_111319\r\n",
      "12.bifpn_3l_1dtst_effnetb3_20200305_134355\r\n",
      "12.bifpn_3l_1dtst_seres50_tta_20200305_172219\r\n",
      "13.bifpn_3l_3dtst_effnetb3_resume_20200305_230828\r\n",
      "13.bifpn_4l_3dtst_effnetb5_hard_augs_20200306_133212\r\n",
      "13.bifpn_4l_3dtst_seres101_better_hard_augs_20200307_113601\r\n",
      "13.bifpn_4l_3dtst_seres101_hard_augs_20200307_113309\r\n",
      "13.deeplab_3dtst_seres101_hard_augs_20200311_202325\r\n",
      "13.test_bifpn_4l_3dtst_effnetb5_20200305_231118\r\n",
      "14.tune_2dtst_bifpn_4l_effnetb5_20200306_184111\r\n",
      "14.tune_2dtst_bifpn_4l_effnetb5_hard_augs_20200306_232835\r\n",
      "14.tune_2dtst_bifpn_4l_seres101_hard_augs_20200310_210420\r\n",
      "14.tune_2dtst_bifpn_4l_seres101_hard_augs_OS16_20200313_123409\r\n",
      "14.tune_2dtst_deeplab_seres101_hard_augs_20200312_113206\r\n",
      "15.tune_1dtst_bifpn_4l_effnetb5_hard_augs_buildings_only_20200311_001521\r\n",
      "15.tune_1dtst_bifpn_4l_seres101_hard_augs_buildings_only_20200311_101635\r\n",
      "15.tune_1dtst_bifpn_4l_seres101_hard_augs_OS16_20200314_122204\r\n",
      "15.tune_1dtst_deeplab_seres101_hard_augs_buildings_only_20200312_202257\r\n",
      "6.segm_bifpn_2l_dice_hinge_2dtst_20200227_210635\r\n",
      "8.bifpn_reduced_focal_20200302_191335\r\n",
      "8.deeplab_focal_20200302_183406\r\n",
      "8.deeplab_reduced_focal_20200302_183355\r\n",
      "8.deeplab_whinge_20200302_121157\r\n",
      "9.bifpn_3l_3dtst_dice_reduced_focal_20200302_210016\r\n",
      "9.bifpn_3l_3dtst_dice_whinge_20200302_205817\r\n",
      "_inr.1.base_bifpn_3l_seres50_higher_wd_no_lookahead_hard_aug_20200329_103621\r\n",
      "_inr.1.base_fpn_20200318_191957\r\n",
      "_inr.1.base_fpn_higher_wd_20200326_133520\r\n",
      "_inr.1.base_linknet_20200318_191802\r\n",
      "_inr.1.base_unet_20200318_191637\r\n",
      "_inr.1.base_unet_20200326_113937\r\n",
      "_inr.1.base_unet_higher_wd_20200326_114201\r\n",
      "_inr.1.base_unet_seres50_higher_wd_no_lookahead_20200326_152045\r\n",
      "_inr.1.base_unet_seres50_higher_wd_no_lookahead_hard_aug_20200329_102013\r\n"
     ]
    }
   ],
   "source": [
    "!ls logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T11:48:51.127912Z",
     "start_time": "2020-03-29T11:48:46.005743Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-6397179e930c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m ]\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# jit_model = load_from_path(best_models[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mloaded_best_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_from_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_no_grad\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_no_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-6397179e930c>\u001b[0m in \u001b[0;36mload_from_path\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlog_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"logs/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"config.yaml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMODEL_FROM_NAME\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"segm_arch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"arch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model_params\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'model.chpn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"state_dict\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_tools/segmentation_models/segm_fpn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, encoder_name, encoder_weights, pyramid_channels, num_fpn_layers, segmentation_channels, num_classes, merge_policy, last_upsample, output_stride, drop_rate, norm_layer, norm_act, **encoder_params)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mnorm_act\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm_act\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mencoder_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mencoder_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         )\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_tools/segmentation_models/encoders.py\u001b[0m in \u001b[0;36mget_encoder\u001b[0;34m(name, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m#    kwargs['dilated'] = True # dilate resnets for better performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pretrained\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoder_weights\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mENCODER_SHAPES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_tools/models/resnet.py\u001b[0m in \u001b[0;36mse_resnet101\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mse_resnet101\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m     \u001b[0;34m\"\"\"TODO: Add Doc\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_resnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"se_resnet101\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_tools/models/resnet.py\u001b[0m in \u001b[0;36m_resnet\u001b[0;34m(arch, pretrained, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fc.weight\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"last_linear.weight\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fc.bias\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"last_linear.bias\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m     \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pretrained_settings\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_tools/models/resnet.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"layer0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                 \u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"layer0.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    822\u001b[0m                     \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m         \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m         \u001b[0mload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# break load->load reference cycle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(module, prefix)\u001b[0m\n\u001b[1;32m    820\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m                     \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m         \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(module, prefix)\u001b[0m\n\u001b[1;32m    820\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m                     \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m         \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(module, prefix)\u001b[0m\n\u001b[1;32m    820\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m                     \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m         \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(module, prefix)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mlocal_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             module._load_from_state_dict(\n\u001b[0;32m--> 819\u001b[0;31m                 state_dict, prefix, local_metadata, True, missing_keys, unexpected_keys, error_msgs)\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_load_from_state_dict\u001b[0;34m(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\u001b[0m\n\u001b[1;32m    769\u001b[0m                     \u001b[0minput_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                     error_msgs.append('While copying the parameter named \"{}\", '\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def load_from_path(path):\n",
    "    log_path = \"logs/\" + path + \"/\"\n",
    "    config = yaml.load(open(log_path + \"config.yaml\"))\n",
    "    model = MODEL_FROM_NAME[config[\"segm_arch\"]](config[\"arch\"], **config.get(\"model_params\", {})).cuda()\n",
    "    state_dict = torch.load(log_path + 'model.chpn')[\"state_dict\"]\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "    model = pt.tta_wrapper.TTA(\n",
    "        model.eval(), segm=True, h_flip=True, rotation=[90], merge=\"mean\", activation=\"sigmoid\"\n",
    "    )\n",
    "#     jit_model = torch.jit.trace(model, torch.ones((2, 3, 256, 256)).cuda())\n",
    "    apex_model = apex.amp.initialize(model, verbosity=False)\n",
    "    return apex_model\n",
    "\n",
    "best_models = [\n",
    "#     \"10.bifpn_2l_2dtst_reduced_focal_20200303_202324\",\n",
    "#     \"11.bifpn_2l_2dtst_lookahead_cut_20200304_180726\",\n",
    "    \"14.tune_2dtst_bifpn_4l_effnetb5_20200306_184111\",\n",
    "    \"14.tune_2dtst_bifpn_4l_effnetb5_hard_augs_20200306_232835\",\n",
    "    \"14.tune_2dtst_bifpn_4l_seres101_hard_augs_20200310_210420\",\n",
    "    \"14.tune_2dtst_bifpn_4l_seres101_hard_augs_OS16_20200313_123409\",\n",
    "    \"15.tune_1dtst_bifpn_4l_effnetb5_hard_augs_buildings_only_20200311_001521\",\n",
    "    \"15.tune_1dtst_bifpn_4l_seres101_hard_augs_buildings_only_20200311_101635\",\n",
    "    \"15.tune_1dtst_bifpn_4l_seres101_hard_augs_OS16_20200314_122204\",\n",
    "]\n",
    "# jit_model = load_from_path(best_models[0])\n",
    "loaded_best_models = list(map(load_from_path, best_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T11:48:29.324273Z",
     "start_time": "2020-03-29T11:48:00.716Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_single_img(img, merge_by_mean=True, adaptive_thr=True, thr=0.5):\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def make_pred(model):\n",
    "        return to_numpy(model(img.view(1, *img.shape).cuda()).squeeze())\n",
    "    \n",
    "    preds = np.array([make_pred(model) for model in loaded_best_models])\n",
    "    pred = np.mean(preds, axis=0)\n",
    "    if merge_by_mean:\n",
    "        if adaptive_thr:\n",
    "            thr_mask = process_adaptive_thr(pred)\n",
    "        else:\n",
    "            thr_mask = (pred > thr).astype(np.uint8)\n",
    "    else:\n",
    "        if adaptive_thr:\n",
    "            thr_masks = [process_adaptive_thr(p) for p in preds]\n",
    "        else:\n",
    "            thr_masks = (preds > thr).astype(np.uint8)\n",
    "        thr_mask = np.median(thr_masks, axis=0).astype(np.uint8)\n",
    "    return pred, thr_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T11:48:30.542101Z",
     "start_time": "2020-03-29T11:48:30.457531Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loaded_best_models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d5410fb20fe3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m @interact(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mN_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_best_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwidgets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntSlider\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mOFFSET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mOFFSET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontinuous_update\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mthr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwidgets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatSlider\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontinuous_update\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loaded_best_models' is not defined"
     ]
    }
   ],
   "source": [
    "@interact(\n",
    "    N_model=(0, len(loaded_best_models), 1),\n",
    "    N=widgets.IntSlider(min=0 + OFFSET, max=32 + OFFSET, continuous_update=False),\n",
    "    thr=widgets.FloatSlider(0.5, min=0.2, max=0.8, step=0.1, continuous_update=False),\n",
    ")\n",
    "def foo(\n",
    "    dataset=DATASETS.keys(),\n",
    "    N_model=0,\n",
    "    N=0, \n",
    "    offset=(0, 4000, 100),\n",
    "    thr=0.5,\n",
    "    adaptive_thr=True,\n",
    "    overlay_pred=False, \n",
    "    overlay_true=False,\n",
    "    merge_by_mean=True,\n",
    "):\n",
    "    global SINGLE_PRED\n",
    "    N += offset\n",
    "    if \"test\" in dataset:\n",
    "        _, img, _ = DATASETS[dataset][N]\n",
    "        mask = torch.zeros_like(img)\n",
    "    else:\n",
    "        img, mask = DATASETS[dataset][N]\n",
    "    \n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def make_pred(model):\n",
    "        return to_numpy(model(img.view(1, *img.shape).cuda()).squeeze())\n",
    "    if N_model == 0:\n",
    "        pred, thr_mask = process_single_img(img, merge_by_mean, adaptive_thr, thr)\n",
    "#         preds = np.array([make_pred(model) for model in loaded_best_models])\n",
    "#         pred = np.mean(preds, axis=0)\n",
    "#         if merge_by_mean:\n",
    "#             if adaptive_thr:\n",
    "#                 thr_mask = process_adaptive_thr(pred)\n",
    "#             else:\n",
    "#                 thr_mask = (pred > thr).astype(np.uint8)\n",
    "#         else:\n",
    "#             if adaptive_thr:\n",
    "#                 thr_masks = [process_adaptive_thr(p) for p in preds]\n",
    "#             else:\n",
    "#                 thr_masks = (preds > thr).astype(np.uint8)\n",
    "#             thr_mask = np.median(thr_masks, axis=0).astype(np.uint8)\n",
    "    else:\n",
    "        pred = make_pred(loaded_best_models[N_model - 1])\n",
    "        thr_mask = (pred > thr).astype(np.uint8)\n",
    "    \n",
    "    \n",
    "    img = to_numpy(img).swapaxes(0, 2)\n",
    "    img = np.clip((img * STD + MEAN), 0, 1)\n",
    "    mask = to_numpy(mask).swapaxes(0, 2)\n",
    "    mask[:, :, :2] = (mask[:, :, :2] + 1) * 0.5\n",
    "    score = jaccard_score(mask[:,:,2], thr_mask.T, average=\"micro\")\n",
    "    if mask[:,:, 2].sum() == 0 and thr_mask.sum() == 0:\n",
    "        score = 1\n",
    "    img_over = img.copy()\n",
    "    if overlay_pred:\n",
    "        img_over[thr_mask.T == 1] = [1, 0, 0]\n",
    "    if overlay_true:\n",
    "        img_over[mask[:, :, 2] == 1] = [0, 0, 1]\n",
    "        if overlay_pred:\n",
    "            img_over[(mask[:, :, 2] == 1) & (thr_mask.T == 1)] = [1, 0, 1]\n",
    "    pred = np.stack([pred.T] * 3, 2)\n",
    "    thr_mask = np.stack([thr_mask.T] * 3, 2)\n",
    "    if \"test\" in dataset:\n",
    "        stacked = np.hstack([img, img_over, pred])\n",
    "        plt.figure(figsize=(24,8))\n",
    "    else:\n",
    "        stacked = np.hstack([img_over, mask, pred, thr_mask])\n",
    "        plt.figure(figsize=(32,8))\n",
    "    plt.imshow(stacked, cmap=\"gray\")\n",
    "#     plt.title(f\"Jaccard={score:.3f}. Max value: {pred.max():.2f}\", fontdict={\"fontsize\": 25})\n",
    "    plt.axis(\"off\")\n",
    "    SINGLE_PRED = pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T13:47:48.151354Z",
     "start_time": "2020-03-16T13:47:47.754004Z"
    }
   },
   "outputs": [],
   "source": [
    "!rm data/preds/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T13:47:48.918472Z",
     "start_time": "2020-03-16T13:47:48.895175Z"
    }
   },
   "outputs": [],
   "source": [
    "empty_idx = set(np.load(\"empty_test_idx.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T15:05:22.956581Z",
     "start_time": "2020-03-16T13:48:21.665211Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11481/11481 [1:17:01<00:00,  2.48it/s]\n"
     ]
    }
   ],
   "source": [
    "PREDS_PATH = \"data/preds\"\n",
    "n_img = 0\n",
    "# max_preds = []\n",
    "for img, aug_imgs, idx in tqdm(test_dataset512):\n",
    "#     n_img += 1\n",
    "#     if n_img < 6:\n",
    "#         n_img += 1\n",
    "#         continue\n",
    "    if idx in empty_idx:\n",
    "        resized_thr_mask = np.zeros((1024, 1024), dtype=np.uint8)\n",
    "    else:\n",
    "        pred, thr_mask = process_single_img(aug_imgs, merge_by_mean=False, adaptive_thr=True, thr=0.5)\n",
    "    #     max_preds.append((pred.max(), np.percentile(pred, 95), idx))\n",
    "        resized_thr_mask = cv2.resize(thr_mask, (1024, 1024), interpolation=cv2.INTER_NEAREST)\n",
    "    cv2.imwrite(PREDS_PATH + \"/\" + (idx + \".tif\"), resized_thr_mask)\n",
    "#     if n_img > 10:\n",
    "#         break\n",
    "    \n",
    "# print(resized_thr_mask.max())\n",
    "# plt.imshow(resized_thr_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T11:05:49.897362Z",
     "start_time": "2020-03-12T11:05:49.867246Z"
    }
   },
   "outputs": [],
   "source": [
    "max_preds_values, max_preds_names = max_preds[:, :2].astype(float), max_preds[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T11:12:11.144594Z",
     "start_time": "2020-03-12T11:12:11.122184Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_by_name(name):\n",
    "    test_path = \"/home/zakirov/datasets/opencities/test\"\n",
    "    img = cv2.imread(f\"{test_path}/{name}/{name}.tif\")\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T11:20:30.344791Z",
     "start_time": "2020-03-12T11:20:30.015537Z"
    }
   },
   "source": [
    "show_by_name(\"d79626\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T11:20:12.675094Z",
     "start_time": "2020-03-12T11:20:12.644530Z"
    }
   },
   "source": [
    "#  (max_preds_values[:, 1] > 0.1)\n",
    "max_preds[(max_preds_values[:, 0] < 0.5) & (max_preds_values[:, 0] > 0.4) ]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T11:21:44.939542Z",
     "start_time": "2020-03-12T11:21:44.919901Z"
    }
   },
   "source": [
    "np.save(\"empty_test_idx\", max_preds_names[max_preds_values[:, 0] < 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T08:53:31.856402Z",
     "start_time": "2020-03-29T08:53:31.816197Z"
    }
   },
   "outputs": [],
   "source": [
    "count = pt.utils.misc.count_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T08:55:51.205990Z",
     "start_time": "2020-03-29T08:55:48.262759Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24.44, 25.52, 23.77)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet = count(pt.segmentation_models.Unet())[0]\n",
    "fpn = count(pt.segmentation_models.SegmentationFPN())[0]\n",
    "bifpn = count(pt.segmentation_models.SegmentationBiFPN())[0]\n",
    "unet, fpn, bifpn = round(unet / 1e6, 2), round(fpn / 1e6, 2), round(bifpn / 1e6, 2)\n",
    "unet, fpn, bifpn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit9890b48dadda4b3ab35703e845f6f232"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
