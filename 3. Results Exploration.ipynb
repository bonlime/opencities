{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T07:43:35.446829Z",
     "start_time": "2020-02-28T07:43:35.439383Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:100% !important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:100% !important;}</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T07:43:37.696300Z",
     "start_time": "2020-02-28T07:43:35.552402Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as albu\n",
    "import albumentations.pytorch as albu_pt\n",
    "%matplotlib inline\n",
    "\n",
    "import apex\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "import pytorch_tools as pt\n",
    "\n",
    "from src.dataset import OpenCitiesDataset, OpenCitiesTestDataset, InriaTilesDataset\n",
    "from src.augmentations import get_aug\n",
    "from src.callbacks import ThrJaccardScore\n",
    "from pytorch_tools.fit_wrapper.callbacks import SegmCutmix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T07:43:37.705479Z",
     "start_time": "2020-02-28T07:43:37.699483Z"
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "from src.utils import MODEL_FROM_NAME\n",
    "from src.utils import TargetWrapper\n",
    "from pytorch_tools.fit_wrapper.callbacks import Callback\n",
    "from pytorch_tools.utils.misc import to_numpy\n",
    "from src.utils import criterion_from_list\n",
    "from src.utils import ToCudaLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T07:43:38.704384Z",
     "start_time": "2020-02-28T07:43:37.707628Z"
    }
   },
   "outputs": [],
   "source": [
    "SZ = 384\n",
    "BS = 32\n",
    "BUILDINGS_ONLY = False\n",
    "RETURN_DISTANCE = False\n",
    "# RETURN_DISTANCE = True\n",
    "\n",
    "aug = get_aug(\"medium\", SZ)\n",
    "\n",
    "val_aug = get_aug(\"val\", SZ)\n",
    "\n",
    "test_aug = get_aug(\"test\", SZ)\n",
    "\n",
    "val_dtst = OpenCitiesDataset(split=\"val\", transform=val_aug, buildings_only=BUILDINGS_ONLY, return_distance=RETURN_DISTANCE)\n",
    "val_dtld = DataLoader(val_dtst, batch_size=BS, shuffle=False, num_workers=4, drop_last=True)\n",
    "val_dtld_i = iter(val_dtld)\n",
    "\n",
    "train_dtst = OpenCitiesDataset(split=\"train\", transform=aug, buildings_only=BUILDINGS_ONLY, return_distance=RETURN_DISTANCE)\n",
    "train_dtld = DataLoader(train_dtst, batch_size=BS, shuffle=True, num_workers=8, drop_last=True)\n",
    "train_dtld_i = iter(train_dtld)\n",
    "\n",
    "test_dtst = OpenCitiesTestDataset(transform=test_aug)\n",
    "test_dtld = DataLoader(test_dtst, batch_size=BS, shuffle=False, num_workers=8, drop_last=False)\n",
    "test_dtld_i = iter(test_dtld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T07:43:39.225248Z",
     "start_time": "2020-02-28T07:43:38.708022Z"
    }
   },
   "outputs": [],
   "source": [
    "val_dtst_inria = InriaTilesDataset(split=\"val\", transform=val_aug)\n",
    "val_dtst_inria = val_dtst_inria + val_dtst\n",
    "val_dtld_inria = DataLoader(val_dtst_inria, batch_size=BS, shuffle=True, num_workers=8, drop_last=True)\n",
    "\n",
    "train_dtst_inria = InriaTilesDataset(split=\"train\", transform=aug)\n",
    "train_dtld_inria = DataLoader(train_dtst_inria, batch_size=BS, shuffle=True, num_workers=8, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T07:43:39.234320Z",
     "start_time": "2020-02-28T07:43:39.230034Z"
    }
   },
   "outputs": [],
   "source": [
    "val_dtld_gpu = ToCudaLoader(val_dtld)\n",
    "train_dtld_gpu = ToCudaLoader(train_dtld)\n",
    "val_dtld_inria_gpu = ToCudaLoader(val_dtld_inria)\n",
    "train_dtld_inria_gpu = ToCudaLoader(train_dtld_inria)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results exploration"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T17:08:31.333511Z",
     "start_time": "2020-02-27T17:08:31.324891Z"
    }
   },
   "source": [
    "count = 0\n",
    "\n",
    "def plusone(w):\n",
    "    global count\n",
    "    print(count)\n",
    "    count +=1\n",
    "\n",
    "w = widgets.Button(description='Click me')\n",
    "w.on_click(plusone)\n",
    "display(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T07:44:10.257698Z",
     "start_time": "2020-02-28T07:44:08.779069Z"
    }
   },
   "outputs": [],
   "source": [
    "PREV_WEIGHTS = None\n",
    "PREDS = None\n",
    "LOADER = val_dtld_gpu\n",
    "# LOADER = val_dtld_inria_gpu\n",
    "IMGS, MASKS = next(iter(LOADER))\n",
    "MEAN=(0.485, 0.456, 0.406)\n",
    "STD=(0.229, 0.224, 0.225)\n",
    "# IMGS, MASKS = IMGS.cpu(), MASKS.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T07:44:10.292624Z",
     "start_time": "2020-02-28T07:44:10.260428Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f5abe395df4945abe7f3af6d013100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='weights', options=('2.deeplab_nov_20200212_171538', '2.deeplab_novâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(\n",
    "    weights=sorted(os.listdir(\"logs/\")),\n",
    "    N=widgets.IntSlider(min=0, max=BS, continuous_update=True),\n",
    "    thr=widgets.FloatSlider(0.5, min=0.2, max=0.8, step=0.1, continuous_update=False),\n",
    ")\n",
    "def foo(weights=None, N=0, thr=0.5):\n",
    "    global PREV_WEIGHTS\n",
    "    global PREDS\n",
    "#     global PREV_IMGS_MASKS_PREDS\n",
    "    \n",
    "    if weights is None:\n",
    "        print(\"select weights\")\n",
    "        return \n",
    "    \n",
    "    if weights != PREV_WEIGHTS:\n",
    "        PREV_WEIGHTS = weights\n",
    "        log_path = \"logs/\" + weights + \"/\"\n",
    "        config = yaml.load(open(log_path + \"config.yaml\"))\n",
    "        model = MODEL_FROM_NAME[config[\"segm_arch\"]](config[\"arch\"], encoder_weights=None, **config.get(\"model_params\", {})).cuda()\n",
    "        model.load_state_dict(torch.load(log_path + 'model.chpn')[\"state_dict\"], strict=False)\n",
    "        \n",
    "#         val_loader = PyTorchDALIWrapper(\n",
    "#             5 if config[\"use_diff\"] else 4, \n",
    "#             data_dir='/home/zakirov/datasets/kamni_clear/old_val/', \n",
    "#             train=False, \n",
    "#             crop_size=512, \n",
    "#             batch_size=8,\n",
    "#             use_diff=config[\"use_diff\"],\n",
    "#         )\n",
    "#         imgs, masks = next(iter(val_loader))\n",
    "        with torch.no_grad():\n",
    "            PREDS = model(IMGS).cpu().detach().sigmoid()\n",
    "        del model\n",
    "#         del val_loader\n",
    "#         PREV_IMGS_MASKS_PREDS = (imgs, masks, preds)\n",
    "        \n",
    "    \n",
    "#     (IMGS, MASKS, PREDS) = PREV_IMGS_MASKS_PREDS\n",
    "#     if True:\n",
    "#         diff = to_numpy(IMGS[N, 3]) \n",
    "#         diff = (diff + 1) * 0.5\n",
    "#         clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "#         diff = clahe.apply((diff * 255).astype(np.uint8)) / 255\n",
    "#     else:\n",
    "#         diff = to_numpy(imgs[N, :3])\n",
    "\n",
    "    img = to_numpy(IMGS[N]).swapaxes(0, 2)\n",
    "    img = np.clip((img * STD + MEAN), 0, 1)\n",
    "#     print(img.min(), img.max())\n",
    "    mask = to_numpy(MASKS[N]).swapaxes(0, 2)\n",
    "    mask[:, :, :2] = (mask[:, :, :2] + 1) * 0.5\n",
    "#     print(mask.min(), mask.max())\n",
    "    pred = np.repeat(to_numpy(PREDS[N]), 3, 0).swapaxes(0, 2)\n",
    "    thr_mask = (pred > thr)\n",
    "#     print(pred.min(), pred.max())\n",
    "    stacked = np.hstack([img, mask, pred, thr_mask])\n",
    "    plt.figure(figsize=(32,8))\n",
    "    plt.imshow(stacked, cmap=\"gray\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit9890b48dadda4b3ab35703e845f6f232"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
